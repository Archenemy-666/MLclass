# Setting up ML
feature classification 
feature combination 
Training data fed to the system
	- understanding and cleaning consistancies and inconsistancies in the dataset.
# Language Bias:

# Search Bias:
Gradient descent 
dynamic programming
Divide and conduer 
Evolutionary computation

# Inductive Bias :
Only considers correct predictions for training data._(takes consistant models)_
___when there is no information about a possibility then its a loop hole  then a rationale needs to be introduced , could be an assumption( this is inductive bias )___

__Without the Bias there is no Generalization.__
How each ML model is different based on the inductive bias. 

## Types of Inductive Bias:
1. Language / restriction Bias 
2. Search / Preferance Bias

## Examples:
- seperating +ve to -ve points (here we can assume a point to be +ve or -ve group based on the biased limits that you set). this could involve a physical line, curve seperating the points. 


# What can go wrong with ML:
- A direct answer and looking for one that can fit all tasks is something that can go wrong.
- __Overfitting and Underfitting__ -> stemmed from Inductive Bias 
- Sometimes a curve should be considered when you are working with regression where we consider the attributes of the dataset.

# Note :
- ill posed porblem -> ML (multiple solutions)
- unbiased is completely useless
- not possible to generalize training data to test data with unbiazed approach. [understanding bias]((https://arize.com/blog/understanding-bias-in-ml-models/)
- linear is language bias, mid point line is preferece bias.
- If the language bias is over-expressive then leads to overfitting.
 

# TO DO 
- Learn about curves/lines/graph theory.
- __Next Week Decision Tree.__
- [understanding bias]((https://arize.com/blog/understanding-bias-in-ml-models/)
- Percent plot
- overfitting and underfitting
- classification v/s regression
- QUIZ (20 min) Due on monday

# Questions 
1. Do we manually pick the inconcsistancies or the outliers are seen after test.
2. 
